---
stages:
- name: BUILD
  inputs:
  - type: git
    branch: master
    service: ${GIT_REPO}    
  triggers:
  - type: commit
  properties:
  - name: DOCKER_ROOT
    value: .
    type: text
  - name: DOCKER_FILE
    value: Dockerfile
    type: text  
  jobs:
  - name: Pre-build check
    type: builder
    build_type: cr
    artifact_dir: ''
    target:
      region_id: ${REGISTRY_REGION_ID}
      api_key: ${API_KEY}
    namespace: ${REGISTRY_NAMESPACE}
    image_name: ${CF_APP_NAME}
    script: |-
      #!/bin/bash
      # uncomment to debug the script
      # set -x
      # copy the script below into your app code repo (e.g. ./scripts/check_prebuild.sh) and 'source' it from your pipeline job
      #    source ./scripts/check_prebuild.sh
      # alternatively, you can source it from online script:
      #    source <(curl -sSL "https://raw.githubusercontent.com/open-toolchain/commons/master/scripts/check_prebuild.sh")
      # ------------------
      # source: https://raw.githubusercontent.com/open-toolchain/commons/master/scripts/check_prebuild.sh
      echo "REGISTRY_URL=${REGISTRY_URL}"
      echo "REGISTRY_NAMESPACE=${REGISTRY_NAMESPACE}"
      echo "IMAGE_NAME=${IMAGE_NAME}"
      echo "ARCHIVE_DIR=${ARCHIVE_DIR}"
      echo "DOCKER_ROOT=${DOCKER_ROOT}"
      echo "DOCKER_FILE=${DOCKER_FILE}"

      # View build properties
      if [ -f build.properties ]; then 
        echo "build.properties:"
        cat build.properties
      else 
        echo "build.properties : not found"
      fi 
      # also run 'env' command to find all available env variables
      # or learn more about the available environment variables at:
      # https://console.bluemix.net/docs/services/ContinuousDelivery/pipeline_deploy_var.html#deliverypipeline_environment

      echo "=========================================================="
      echo "Checking for Dockerfile at the repository root"
      if [ -z "${DOCKER_ROOT}" ]; then DOCKER_ROOT=. ; fi
      if [ -z "${DOCKER_FILE}" ]; then DOCKER_FILE=Dockerfile ; fi
      if [ -f ${DOCKER_ROOT}/${DOCKER_FILE} ]; then 
      echo -e "Dockerfile found at: ${DOCKER_FILE}"
      else
          echo "Dockerfile not found at: ${DOCKER_FILE}"
          exit 1
      fi
      echo "Linting Dockerfile"
      npm install -g dockerlint
      dockerlint -f ${DOCKER_ROOT}/${DOCKER_FILE}

      echo "=========================================================="
      echo "Checking registry current plan and quota"
      bx cr plan
      bx cr quota
      echo "If needed, discard older images using: bx cr image-rm"
      echo "Checking registry namespace: ${REGISTRY_NAMESPACE}"
      NS=$( bx cr namespaces | grep ${REGISTRY_NAMESPACE} ||: )
      if [ -z "${NS}" ]; then
          echo "Registry namespace ${REGISTRY_NAMESPACE} not found, creating it."
          bx cr namespace-add ${REGISTRY_NAMESPACE}
          echo "Registry namespace ${REGISTRY_NAMESPACE} created."
      else 
          echo "Registry namespace ${REGISTRY_NAMESPACE} found."
      fi
      echo -e "Existing images in registry"
      bx cr images --restrict ${REGISTRY_NAMESPACE}
      # echo "=========================================================="
      # KEEP=1
      # echo -e "PURGING REGISTRY, only keeping last ${KEEP} image(s) based on image digests"
      # COUNT=0
      # LIST=$( bx cr images --restrict ${REGISTRY_NAMESPACE}/${IMAGE_NAME} --no-trunc --format '{{ .Created }} {{ .Repository }}@{{ .Digest }}' | sort -r -u | awk '{print $2}' | sed '$ d' )
      # while read -r IMAGE_URL ; do
      #   if [[ "$COUNT" -lt "$KEEP" ]]; then
      #     echo "Keeping image digest: ${IMAGE_URL}"
      #   else
      #     bx cr image-rm "${IMAGE_URL}"
      #   fi
      #   COUNT=$((COUNT+1)) 
      # done <<< "$LIST"
      # if [[ "$COUNT" -gt 1 ]]; then
      #   echo "Content of image registry"
      #   bx cr images
      # fi
  - name: Build Docker image
    type: builder
    build_type: cr
    artifact_dir: output
    target:
      region_id: ${REGISTRY_REGION_ID}
      api_key: ${API_KEY}
    namespace: ${REGISTRY_NAMESPACE}
    image_name: ${CF_APP_NAME}
    script: |
      #!/bin/bash
      # uncomment to debug the script
      #set -x
      # copy the script below into your app code repo (e.g. ./scripts/build_image.sh) and 'source' it from your pipeline job
      #    source ./scripts/build_image.sh
      # alternatively, you can source it from online script:
      #    source <(curl -sSL "https://raw.githubusercontent.com/open-toolchain/commons/master/scripts/build_image.sh")
      # ------------------
      # source: https://raw.githubusercontent.com/open-toolchain/commons/master/scripts/build_image.sh

      # This script does build a Docker image into IBM Container Service private image registry, and copies information into
      # a build.properties file, so they can be reused later on by other scripts (e.g. image url, chart name, ...)
      echo "REGISTRY_URL=${REGISTRY_URL}"
      echo "REGISTRY_NAMESPACE=${REGISTRY_NAMESPACE}"
      echo "IMAGE_NAME=${IMAGE_NAME}"
      echo "BUILD_NUMBER=${BUILD_NUMBER}"
      echo "ARCHIVE_DIR=${ARCHIVE_DIR}"
      echo "GIT_BRANCH=${GIT_BRANCH}"
      echo "GIT_COMMIT=${GIT_COMMIT}"
      echo "DOCKER_ROOT=${DOCKER_ROOT}"
      echo "DOCKER_FILE=${DOCKER_FILE}"

      # View build properties
      if [ -f build.properties ]; then 
        echo "build.properties:"
        cat build.properties
      else 
        echo "build.properties : not found"
      fi 
      # also run 'env' command to find all available env variables
      # or learn more about the available environment variables at:
      # https://console.bluemix.net/docs/services/ContinuousDelivery/pipeline_deploy_var.html#deliverypipeline_environment

      # To review or change build options use:
      # bx cr build --help

      echo -e "Existing images in registry"
      bx cr images

      # Minting image tag using format: BRANCH-BUILD_NUMBER-COMMIT_ID-TIMESTAMP
      # e.g. master-3-50da6912-20181123114435

      TIMESTAMP=$( date -u "+%Y%m%d%H%M%S")
      IMAGE_TAG=${TIMESTAMP}
      if [ ! -z "${GIT_COMMIT}" ]; then
        GIT_COMMIT_SHORT=$( echo ${GIT_COMMIT} | head -c 8 ) 
        IMAGE_TAG=${GIT_COMMIT_SHORT}-${IMAGE_TAG}
      fi
      IMAGE_TAG=${BUILD_NUMBER}-${IMAGE_TAG}
      if [ ! -z "${GIT_BRANCH}" ]; then IMAGE_TAG=${GIT_BRANCH}-${IMAGE_TAG} ; fi
      echo "=========================================================="
      echo -e "BUILDING CONTAINER IMAGE: ${IMAGE_NAME}:${IMAGE_TAG}"
      if [ -z "${DOCKER_ROOT}" ]; then DOCKER_ROOT=. ; fi
      if [ -z "${DOCKER_FILE}" ]; then DOCKER_FILE=${DOCKER_ROOT}/Dockerfile ; fi
      set -x
      bx cr build -t ${REGISTRY_URL}/${REGISTRY_NAMESPACE}/${IMAGE_NAME}:${IMAGE_TAG} ${DOCKER_ROOT} -f ${DOCKER_FILE}
      set +x

      bx cr image-inspect ${REGISTRY_URL}/${REGISTRY_NAMESPACE}/${IMAGE_NAME}:${IMAGE_TAG}

      # Set PIPELINE_IMAGE_URL for subsequent jobs in stage (e.g. Vulnerability Advisor)
      export PIPELINE_IMAGE_URL="$REGISTRY_URL/$REGISTRY_NAMESPACE/$IMAGE_NAME:$IMAGE_TAG"

      bx cr images --restrict ${REGISTRY_NAMESPACE}/${IMAGE_NAME}

      ######################################################################################
      # Copy any artifacts that will be needed for deployment and testing to $WORKSPACE    #
      ######################################################################################
      echo "=========================================================="
      echo "COPYING ARTIFACTS needed for deployment and testing (in particular build.properties)"

      echo "Checking archive dir presence"
      if [ -z "${ARCHIVE_DIR}" ]; then
        echo -e "Build archive directory contains entire working directory."
      else
        echo -e "Copying working dir into build archive directory: ${ARCHIVE_DIR} "
        mkdir -p ${ARCHIVE_DIR}
        find . -mindepth 1 -maxdepth 1 -not -path "./$ARCHIVE_DIR" -exec cp -R '{}' "${ARCHIVE_DIR}/" ';'
      fi

      # Persist env variables into a properties file (build.properties) so that all pipeline stages consuming this
      # build as input and configured with an environment properties file valued 'build.properties'
      # will be able to reuse the env variables in their job shell scripts.

      # If already defined build.properties from prior build job, append to it.
      cp build.properties $ARCHIVE_DIR/ || :

      # IMAGE information from build.properties is used in Helm Chart deployment to set the release name
      echo "IMAGE_NAME=${IMAGE_NAME}" >> $ARCHIVE_DIR/build.properties
      echo "IMAGE_TAG=${IMAGE_TAG}" >> $ARCHIVE_DIR/build.properties
      # REGISTRY information from build.properties is used in Helm Chart deployment to generate cluster secret
      echo "REGISTRY_URL=${REGISTRY_URL}" >> $ARCHIVE_DIR/build.properties
      echo "REGISTRY_NAMESPACE=${REGISTRY_NAMESPACE}" >> $ARCHIVE_DIR/build.properties
      echo "GIT_BRANCH=${GIT_BRANCH}" >> $ARCHIVE_DIR/build.properties
      echo "File 'build.properties' created for passing env variables to subsequent pipeline jobs:"
      cat $ARCHIVE_DIR/build.properties
- name: VALIDATE
  inputs:
  - type: job
    stage: BUILD
    job: Build Docker image
  triggers:
  - type: stage
  properties:
  - name: buildprops
    value: build.properties
    type: file
  jobs:
  - name: Vulnerability Advisor
    type: tester
    test_type: vulnerabilityadvisor
    use_image_from_build_input: true
    fail_stage: false
    target:
      region_id: ${REGISTRY_REGION_ID}
      api_key: ${API_KEY}
    script: |
      #!/bin/bash
      # uncomment to debug the script
      # set -x
      # copy the script below into your app code repo (e.g. ./scripts/check_vulnerabilities.sh) and 'source' it from your pipeline job
      #    source ./scripts/check_vulnerabilities.sh
      # alternatively, you can source it from online script:
      #    source <(curl -sSL "https://raw.githubusercontent.com/open-toolchain/commons/master/scripts/check_vulnerabilities.sh")
      # ------------------
      # source: https://raw.githubusercontent.com/open-toolchain/commons/master/scripts/check_vulnerabilities.sh
      # Input env variables (can be received via a pipeline environment properties.file.

      # View build properties
      if [ -f build.properties ]; then 
        echo "build.properties:"
        cat build.properties
      else 
        echo "build.properties : not found"
      fi 

      # If running after build_image.sh in same stage, reuse the exported variable PIPELINE_IMAGE_URL
      if [ -z "${PIPELINE_IMAGE_URL}" ]; then
        PIPELINE_IMAGE_URL=${REGISTRY_URL}/${REGISTRY_NAMESPACE}/${IMAGE_NAME}:${IMAGE_TAG}
      else
        # extract from img url
        REGISTRY_URL=$(echo ${PIPELINE_IMAGE_URL} | cut -f1 -d/)
        REGISTRY_NAMESPACE=$(echo ${PIPELINE_IMAGE_URL} | cut -f2 -d/)
        IMAGE_NAME=$(echo ${PIPELINE_IMAGE_URL} | cut -f3 -d/ | cut -f1 -d:)
        IMAGE_TAG=$(echo ${PIPELINE_IMAGE_URL} | cut -f3 -d/ | cut -f2 -d:)
      fi
      echo "PIPELINE_IMAGE_URL=${PIPELINE_IMAGE_URL}"
      echo "REGISTRY_URL=${REGISTRY_URL}"
      echo "REGISTRY_NAMESPACE=${REGISTRY_NAMESPACE}"
      echo "IMAGE_NAME=${IMAGE_NAME}"
      echo "IMAGE_TAG=${IMAGE_TAG}"

      # also run 'env' command to find all available env variables
      # or learn more about the available environment variables at:
      # https://console.bluemix.net/docs/services/ContinuousDelivery/pipeline_deploy_var.html#deliverypipeline_environment

      bx cr images --restrict ${REGISTRY_NAMESPACE}/${IMAGE_NAME}
      echo -e "Checking vulnerabilities in image: ${PIPELINE_IMAGE_URL}"
      for ITER in {1..30}
      do
        set +e
        STATUS=$( bx cr va -e -o json ${PIPELINE_IMAGE_URL} | jq -r '.[0].status' )
        set -e
        # Possible status from Vulnerability Advisor: OK, UNSUPPORTED, INCOMPLETE, UNSCANNED, FAIL, WARN
        if [[ ${STATUS} != "INCOMPLETE" && ${STATUS} != "UNSCANNED" ]]; then
          break
        fi
        echo -e "${ITER} STATUS ${STATUS} : A vulnerability report was not found for the specified image."
        echo "Either the image doesn't exist or the scan hasn't completed yet. "
        echo "Waiting for scan to complete..."
        sleep 10
      done
      set +e
      bx cr va -e ${PIPELINE_IMAGE_URL}
      set -e
      STATUS=$( bx cr va -e -o json ${PIPELINE_IMAGE_URL} | jq -r '.[0].status' )
      [[ ${STATUS} == "OK" ]] || [[ ${STATUS} == "UNSUPPORTED" ]] || [[ ${STATUS} == "WARN" ]] || { echo "ERROR: The vulnerability scan was not successful, check the OUTPUT of the command and try again."; exit 1; }
- name: PROD
  inputs:
  - type: job
    stage: BUILD
    job: Build Docker image
  triggers:
  - type: stage
  properties:
  - name: buildprops
    value: build.properties
    type: file
  - name: CLUSTER_NAMESPACE
    value: ${PROD_CLUSTER_NAMESPACE}
    type: text
  - name: DEPLOYMENT_FILE
    value: deployment.yml
    type: text      
  jobs:
  - name: Pre-deploy check
    type: deployer
    target:
      region_id: ${PROD_REGION_ID}
      api_key: ${API_KEY}
      kubernetes_cluster: ${PROD_CLUSTER_NAME}
    script: |
      #!/bin/bash
      # uncomment to debug the script
      #set -x
      # copy the script below into your app code repo (e.g. ./scripts/check_predeploy.sh) and 'source' it from your pipeline job
      #    source ./scripts/check_predeploy_kubectl.sh
      # alternatively, you can source it from online script:
      #    source <(curl -sSL "https://raw.githubusercontent.com/open-toolchain/commons/master/scripts/check_predeploy_kubectl.sh")
      # ------------------
      # source: https://raw.githubusercontent.com/open-toolchain/commons/master/scripts/check_predeploy_kubectl.sh

      # This script checks the IBM Container Service cluster is ready, has a namespace configured with access to the private
      # image registry (using an IBM Cloud API Key). It also configures Helm Tiller service to later perform a deploy with Helm.

      # Input env variables (can be received via a pipeline environment properties.file.
      echo "IMAGE_NAME=${IMAGE_NAME}"
      echo "IMAGE_TAG=${IMAGE_TAG}"
      echo "REGISTRY_URL=${REGISTRY_URL}"
      echo "REGISTRY_NAMESPACE=${REGISTRY_NAMESPACE}"

      # View build properties
      if [ -f build.properties ]; then 
        echo "build.properties:"
        cat build.properties
      else 
        echo "build.properties : not found"
      fi 
      # also run 'env' command to find all available env variables
      # or learn more about the available environment variables at:
      # https://console.bluemix.net/docs/services/ContinuousDelivery/pipeline_deploy_var.html#deliverypipeline_environment

      # Input env variables from pipeline job
      echo "PIPELINE_KUBERNETES_CLUSTER_NAME=${PIPELINE_KUBERNETES_CLUSTER_NAME}"
      echo "CLUSTER_NAMESPACE=${CLUSTER_NAMESPACE}"

      echo "=========================================================="
      echo "CHECKING DEPLOYMENT.YML manifest"
      #Update deployment.yml with image name
      if [ -z "${DEPLOYMENT_FILE}" ]; then DEPLOYMENT_FILE=deployment.yml ; fi
      if [ ! -f ${DEPLOYMENT_FILE} ]; then
          echo -e "${red}Kubernetes deployment file '${DEPLOYMENT_FILE}' not found${no_color}"
          exit 1
      fi

      #Check cluster availability
      echo "=========================================================="
      echo "CHECKING CLUSTER readiness and namespace existence"
      IP_ADDR=$( bx cs workers ${PIPELINE_KUBERNETES_CLUSTER_NAME} | grep normal | awk '{ print $2 }' )
      if [ -z "${IP_ADDR}" ]; then
        echo -e "${PIPELINE_KUBERNETES_CLUSTER_NAME} not created or workers not ready"
        exit 1
      fi
      echo "Configuring cluster namespace"
      if kubectl get namespace ${CLUSTER_NAMESPACE}; then
        echo -e "Namespace ${CLUSTER_NAMESPACE} found."
      else
        kubectl create namespace ${CLUSTER_NAMESPACE}
        echo -e "Namespace ${CLUSTER_NAMESPACE} created."
      fi

      # Grant access to private image registry from namespace $CLUSTER_NAMESPACE
      # reference https://console.bluemix.net/docs/containers/cs_cluster.html#bx_registry_other
      echo "=========================================================="
      echo -e "CONFIGURING ACCESS to private image registry from namespace ${CLUSTER_NAMESPACE}"
      IMAGE_PULL_SECRET_NAME="ibmcloud-toolchain-${PIPELINE_TOOLCHAIN_ID}-${REGISTRY_URL}"

      echo -e "Checking for presence of ${IMAGE_PULL_SECRET_NAME} imagePullSecret for this toolchain"
      if ! kubectl get secret ${IMAGE_PULL_SECRET_NAME} --namespace ${CLUSTER_NAMESPACE}; then
        echo -e "${IMAGE_PULL_SECRET_NAME} not found in ${CLUSTER_NAMESPACE}, creating it"
        # for Container Registry, docker username is 'token' and email does not matter
        kubectl --namespace ${CLUSTER_NAMESPACE} create secret docker-registry ${IMAGE_PULL_SECRET_NAME} --docker-server=${REGISTRY_URL} --docker-password=${PIPELINE_BLUEMIX_API_KEY} --docker-username=iamapikey --docker-email=a@b.com
      else
        echo -e "Namespace ${CLUSTER_NAMESPACE} already has an imagePullSecret for this toolchain."
      fi
      SERVICE_ACCOUNT=$(kubectl get serviceaccount default  -o json --namespace ${CLUSTER_NAMESPACE} )
      if ! echo ${SERVICE_ACCOUNT} | jq -e '. | has("imagePullSecrets")' > /dev/null ; then
        kubectl patch --namespace ${CLUSTER_NAMESPACE} serviceaccount/default -p '{"imagePullSecrets":[{"name":"'"${IMAGE_PULL_SECRET_NAME}"'"}]}'
      else
        if echo ${SERVICE_ACCOUNT} | jq -e '.imagePullSecrets[] | select(.name=="'"${IMAGE_PULL_SECRET_NAME}"'")' > /dev/null ; then 
          echo -e "Pull secret already found in default serviceAccount"
        else
          echo "Inserting toolchain pull secret into default serviceAccount"
          kubectl patch --namespace ${CLUSTER_NAMESPACE} serviceaccount/default --type='json' -p='[{"op":"add","path":"/imagePullSecrets/-","value":{"name": "'"${IMAGE_PULL_SECRET_NAME}"'"}}]'
        fi
      fi
      echo "default serviceAccount:"
      kubectl get serviceaccount default --namespace ${CLUSTER_NAMESPACE} -o yaml
      echo -e "Namespace ${CLUSTER_NAMESPACE} authorizing with private image registry using patched default serviceAccount"
  - name: Deploy to Kubernetes
    type: deployer
    target:
      region_id: ${PROD_REGION_ID}
      api_key: ${API_KEY}
      kubernetes_cluster: ${PROD_CLUSTER_NAME}
    script: |
      #!/bin/bash
      # uncomment to debug the script
      #set -x
      # copy the script below into your app code repo (e.g. ./scripts/deploy_kubectl.sh) and 'source' it from your pipeline job
      #    source ./scripts/deploy_kubectl.sh
      # alternatively, you can source it from online script:
      #    source <(curl -sSL "https://raw.githubusercontent.com/open-toolchain/commons/master/scripts/deploy_kubectl.sh")
      # ------------------
      # source: https://raw.githubusercontent.com/open-toolchain/commons/master/scripts/deploy_kubectl.sh
      # Input env variables (can be received via a pipeline environment properties.file.
      echo "IMAGE_NAME=${IMAGE_NAME}"
      echo "IMAGE_TAG=${IMAGE_TAG}"
      echo "REGISTRY_URL=${REGISTRY_URL}"
      echo "REGISTRY_NAMESPACE=${REGISTRY_NAMESPACE}"
      echo "DEPLOYMENT_FILE=${DEPLOYMENT_FILE}"

      #View build properties
      # cat build.properties
      # also run 'env' command to find all available env variables
      # or learn more about the available environment variables at:
      # https://console.bluemix.net/docs/services/ContinuousDelivery/pipeline_deploy_var.html#deliverypipeline_environment

      # Input env variables from pipeline job
      echo "PIPELINE_KUBERNETES_CLUSTER_NAME=${PIPELINE_KUBERNETES_CLUSTER_NAME}"
      if [ -z "${CLUSTER_NAMESPACE}" ]; then CLUSTER_NAMESPACE=default ; fi
      echo "CLUSTER_NAMESPACE=${CLUSTER_NAMESPACE}"

      echo "=========================================================="
      echo "DEPLOYING using manifest"
      echo -e "Updating ${DEPLOYMENT_FILE} with image name: ${REGISTRY_URL}/${REGISTRY_NAMESPACE}/${IMAGE_NAME}:${IMAGE_TAG}"
      if [ -z "${DEPLOYMENT_FILE}" ]; then DEPLOYMENT_FILE=deployment.yml ; fi
      if [ -f ${DEPLOYMENT_FILE} ]; then
          sed -i "s~^\([[:blank:]]*\)image:.*$~\1image: ${REGISTRY_URL}/${REGISTRY_NAMESPACE}/${IMAGE_NAME}:${IMAGE_TAG}~" ${DEPLOYMENT_FILE}
          cat ${DEPLOYMENT_FILE}
      else 
          echo -e "${red}Kubernetes deployment file '${DEPLOYMENT_FILE}' not found${no_color}"
          exit 1
      fi    
      set -x
      kubectl apply --namespace ${CLUSTER_NAMESPACE} -f ${DEPLOYMENT_FILE} 
      set +x

      echo ""
      echo "=========================================================="
      IMAGE_REPOSITORY=${REGISTRY_URL}/${REGISTRY_NAMESPACE}/${IMAGE_NAME}
      echo -e "CHECKING deployment status of ${IMAGE_REPOSITORY}:${IMAGE_TAG}"
      echo ""
      for ITERATION in {1..30}
      do
        DATA=$( kubectl get pods --namespace ${CLUSTER_NAMESPACE} -o json )
        NOT_READY=$( echo $DATA | jq '.items[].status | select(.containerStatuses!=null) | .containerStatuses[] | select(.image=="'"${IMAGE_REPOSITORY}:${IMAGE_TAG}"'") | select(.ready==false) ' )
        if [[ -z "$NOT_READY" ]]; then
          echo -e "All pods are ready:"
          echo $DATA | jq '.items[].status | select(.containerStatuses!=null) | .containerStatuses[] | select(.image=="'"${IMAGE_REPOSITORY}:${IMAGE_TAG}"'") | select(.ready==true) '
          break # deployment succeeded
        fi
        REASON=$(echo $DATA | jq '.items[].status | select(.containerStatuses!=null) | .containerStatuses[] | select(.image=="'"${IMAGE_REPOSITORY}:${IMAGE_TAG}"'") | .state.waiting.reason')
        echo -e "${ITERATION} : Deployment still pending..."
        echo -e "NOT_READY:${NOT_READY}"
        echo -e "REASON: ${REASON}"
        if [[ ${REASON} == *ErrImagePull* ]] || [[ ${REASON} == *ImagePullBackOff* ]]; then
          echo "Detected ErrImagePull or ImagePullBackOff failure. "
          echo "Please check proper authenticating to from cluster to image registry (e.g. image pull secret)"
          break; # no need to wait longer, error is fatal
        elif [[ ${REASON} == *CrashLoopBackOff* ]]; then
          echo "Detected CrashLoopBackOff failure. "
          echo "Application is unable to start, check the application startup logs"
          break; # no need to wait longer, error is fatal
        fi
        sleep 5
      done

      APP_NAME=$(kubectl get pods --namespace ${CLUSTER_NAMESPACE} -o json | jq -r '.items[].status | select(.containerStatuses!=null) | .containerStatuses[] | select(.image=="'"${IMAGE_REPOSITORY}:${IMAGE_TAG}"'") | .name' | head -n 1)
      echo -e "APP: ${APP_NAME}"
      echo "DEPLOYED PODS:"
      kubectl describe pods --selector app=${APP_NAME} --namespace ${CLUSTER_NAMESPACE}
      if [ ! -z "${APP_NAME}" ]; then
        APP_SERVICE=$(kubectl get services --namespace ${CLUSTER_NAMESPACE} -o json | jq -r ' .items[] | select (.spec.selector.app=="'"${APP_NAME}"'") | .metadata.name ')
        echo -e "SERVICE: ${APP_SERVICE}"
        echo "DEPLOYED SERVICES:"
        kubectl describe services ${APP_SERVICE} --namespace ${CLUSTER_NAMESPACE}
      fi
      #echo "Application Logs"
      #kubectl logs --selector app=${APP_NAME} --namespace ${CLUSTER_NAMESPACE}  
      echo ""
      if [[ ! -z "$NOT_READY" ]]; then
        echo ""
        echo "=========================================================="
        echo "DEPLOYMENT FAILED"
        exit 1
      fi

      echo ""
      echo "=========================================================="
      echo "DEPLOYMENT SUCCEEDED"
      if [ ! -z "${APP_SERVICE}" ]; then
        echo ""
        IP_ADDR=$(bx cs workers ${PIPELINE_KUBERNETES_CLUSTER_NAME} | grep normal | head -n 1 | awk '{ print $2 }')
        PORT=$( kubectl get services --namespace ${CLUSTER_NAMESPACE} | grep ${APP_SERVICE} | sed 's/.*:\([0-9]*\).*/\1/g' )
        echo ""
        echo -e "VIEW THE APPLICATION AT: http://${IP_ADDR}:${PORT}"
      fi